{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8150909,"sourceType":"datasetVersion","datasetId":4773550},{"sourceId":31710,"sourceType":"modelInstanceVersion","modelInstanceId":26595}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install monai\n!pip install lightning\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T20:29:03.940231Z","iopub.execute_input":"2024-04-18T20:29:03.940506Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.3.0-202310121228-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\nDownloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil\nimport glob\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n#import nibabel as nib\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\nfrom torchmetrics.classification import BinaryJaccardIndex, Dice, JaccardIndex\nimport torch.distributed as dist\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport torch.multiprocessing as mp\nfrom torch.nn.modules.loss import BCEWithLogitsLoss\nfrom monai.losses.dice import *","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:57:10.412902Z","iopub.execute_input":"2024-04-18T17:57:10.413218Z","iopub.status.idle":"2024-04-18T17:58:00.279215Z","shell.execute_reply.started":"2024-04-18T17:57:10.413190Z","shell.execute_reply":"2024-04-18T17:58:00.278391Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-18 17:57:51.343944: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-18 17:57:51.344080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-18 17:57:51.511814: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from monai.data import DataLoader \n# , ArrayDataset\n# from torch.optim.lr_scheduler import CosineAnnealingLR\n# from monai.transforms import (\n#     EnsureChannelFirst,\n#     AsDiscrete,\n#     Compose,\n#     LoadImage,\n#     ScaleIntensity,\n# )\nimport pytorch_lightning as pl\nimport lightning\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:00.280261Z","iopub.execute_input":"2024-04-18T17:58:00.280860Z","iopub.status.idle":"2024-04-18T17:58:00.749722Z","shell.execute_reply.started":"2024-04-18T17:58:00.280833Z","shell.execute_reply":"2024-04-18T17:58:00.748891Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"class BraTSDataset(Dataset):    \n    def __init__(self, data_root_folder, folder = '', n_sample=None):\n        main_folder = os.path.join(data_root_folder, folder)\n        self.folder_path = os.path.join(main_folder, 'slice')\n        #self.file_names = sorted(os.listdir(self.folder_path))[:n_sample]\n\n\n    def __getitem__(self, index):\n        file_name = os.listdir(self.folder_path)[index]\n        #file_name = self.file_names[index]\n        sample = np.load(os.path.join(self.folder_path, file_name))\n        #eps = 0.0001\n        img = sample[0,:,:]\n        diff = np.subtract(img.max(), img.min(), dtype=np.float64)\n        denom = np.clip(diff, a_min=1e-8, a_max=None)\n        img = (img - img.min()) / denom\n        mask = sample[1, :, :]\n        mask[mask>0.0] = 1.0\n        mask[mask==0.0] = 0\n        img_as_tensor = np.expand_dims(img, axis=0)\n        mask_as_tensor = np.expand_dims(mask, axis=0)\n        \n        \n        return {\n            'image': img_as_tensor,\n            'mask': mask_as_tensor,\n            'img_id': file_name\n        }\n \n    def __len__(self):\n        return len(os.listdir(self.folder_path))\n        #return len(self.file_names)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:00.751952Z","iopub.execute_input":"2024-04-18T17:58:00.752277Z","iopub.status.idle":"2024-04-18T17:58:00.762217Z","shell.execute_reply.started":"2024-04-18T17:58:00.752250Z","shell.execute_reply":"2024-04-18T17:58:00.761186Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"data_root_folder = '/kaggle/input/brats-dataset/full_raw - Copy'\ntrain_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'train')\nval_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'val')\ntest_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'test')","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:00.763448Z","iopub.execute_input":"2024-04-18T17:58:00.764170Z","iopub.status.idle":"2024-04-18T17:58:00.777144Z","shell.execute_reply.started":"2024-04-18T17:58:00.764136Z","shell.execute_reply":"2024-04-18T17:58:00.776351Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\n#device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:00.778690Z","iopub.execute_input":"2024-04-18T17:58:00.778959Z","iopub.status.idle":"2024-04-18T17:58:00.785969Z","shell.execute_reply.started":"2024-04-18T17:58:00.778937Z","shell.execute_reply":"2024-04-18T17:58:00.785234Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\nvalidation_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=2)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:00.787131Z","iopub.execute_input":"2024-04-18T17:58:00.787868Z","iopub.status.idle":"2024-04-18T17:58:02.820406Z","shell.execute_reply.started":"2024-04-18T17:58:00.787837Z","shell.execute_reply":"2024-04-18T17:58:02.819421Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Sub Classes for U-Net and Attention U-Net","metadata":{}},{"cell_type":"code","source":"class conv_block(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(conv_block, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass resconv_block(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(resconv_block, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n        self.Conv_1x1 = nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, x):\n\n        residual = self.Conv_1x1(x)\n        x = self.conv(x)\n\n        return residual + x\n\n\nclass up_conv(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(up_conv, self).__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.up(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:02.821640Z","iopub.execute_input":"2024-04-18T17:58:02.821996Z","iopub.status.idle":"2024-04-18T17:58:02.836224Z","shell.execute_reply.started":"2024-04-18T17:58:02.821964Z","shell.execute_reply":"2024-04-18T17:58:02.835184Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# U-Net","metadata":{}},{"cell_type":"code","source":"class U_Net(nn.Module):\n    def __init__(self, img_ch=3, output_ch=1, first_layer_numKernel=64, name = \"U_Net\"):\n        super(U_Net, self).__init__()\n        self.name = name\n        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch, ch_out=first_layer_numKernel)\n        self.Conv2 = conv_block(ch_in=first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n        self.Conv3 = conv_block(ch_in=2 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n        self.Conv4 = conv_block(ch_in=4 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n        self.Conv5 = conv_block(ch_in=8 * first_layer_numKernel, ch_out=16 * first_layer_numKernel)\n\n        self.Up5 = up_conv(ch_in=16 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n        self.Up_conv5 = conv_block(ch_in=16 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n\n        self.Up4 = up_conv(ch_in=8 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n        self.Up_conv4 = conv_block(ch_in=8 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n\n        self.Up3 = up_conv(ch_in=4 * first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n        self.Up_conv3 = conv_block(ch_in=4 * first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n\n        self.Up2 = up_conv(ch_in=2 * first_layer_numKernel, ch_out=first_layer_numKernel)\n        self.Up_conv2 = conv_block(ch_in=2 * first_layer_numKernel, ch_out=first_layer_numKernel)\n\n        self.Conv_1x1 = nn.Sequential(\n            nn.Conv2d(first_layer_numKernel, output_ch, kernel_size=1, stride=1, padding=0) # Use sigmoid activation for binary segmentation\n        )\n        # self.Conv_1x1 =  nn.Conv2d(first_layer_numKernel, output_ch, kernel_size = 1, stride = 1, padding = 0)\n\n    def forward(self, x):\n\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n\n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        d5 = torch.cat((x4, d5), dim=1)\n\n        d5 = self.Up_conv5(d5)\n\n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3, d4), dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2, d3), dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1, d2), dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n        \n        return d1","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:02.837348Z","iopub.execute_input":"2024-04-18T17:58:02.837674Z","iopub.status.idle":"2024-04-18T17:58:02.854092Z","shell.execute_reply.started":"2024-04-18T17:58:02.837642Z","shell.execute_reply":"2024-04-18T17:58:02.853188Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def dice_coeff_binary(y_pred, y_true):\n        \"\"\"Values must be only zero or one.\"\"\"\n        y_pred[y_pred >= 0.5] = 1\n        y_pred[y_pred < 0.5] = 0\n        eps = 0.0001\n        inter = torch.dot(y_pred.view(-1).float(), y_true.view(-1).float())\n        union = torch.sum(y_pred.float()) + torch.sum(y_true.float())\n        return ((2 * inter.float() + eps) / (union.float() + eps))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:02.857744Z","iopub.execute_input":"2024-04-18T17:58:02.858091Z","iopub.status.idle":"2024-04-18T17:58:02.866208Z","shell.execute_reply.started":"2024-04-18T17:58:02.858059Z","shell.execute_reply":"2024-04-18T17:58:02.865339Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class U_Net_DDP(pl.LightningModule):\n    def __init__(self, net, lr, loss, jaccard):\n        super().__init__()\n        self.net = net\n        self.lr = lr\n        self.loss = loss \n        #self.dice = dice\n        self.jaccard = jaccard\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        return self.net(x)\n    \n    def training_step(self, batch, batch_idx):\n        imgs = batch['image'].float()\n        true_masks = batch['mask']\n\n        y_pred = self(imgs)\n        loss = self.loss(y_pred, true_masks.float())\n        #y_pred = (y_pred >= 0.5).float()\n        y_pred = self.sigmoid(y_pred)\n        \n\n        batch_dice_score = dice_coeff_binary(y_pred, true_masks)\n        batch_jaccard_score = jaccard_index_metric(y_pred, true_masks)\n        \n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        self.log(\"dice\", batch_dice_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        self.log(\"jaccard\", batch_jaccard_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        imgs = batch['image'].float()\n        true_masks = batch['mask']\n        \n        y_pred = self(imgs)\n        loss = self.loss(y_pred, true_masks.float())\n        #y_pred = (y_pred >= 0.5).float()\n        y_pred = self.sigmoid(y_pred)\n\n        batch_dice_score = dice_coeff_binary(y_pred, true_masks)\n        batch_jaccard_score = jaccard_index_metric(y_pred, true_masks)\n        \n        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        self.log(\"val_dice\", batch_dice_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        self.log(\"val_jaccard\", batch_dice_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        \n        return loss\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n        #scheduler = CosineAnnealingLR(optimizer, self.trainer.max_epochs * 200, 0)\n        return [optimizer] #, [scheduler]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:02.867664Z","iopub.execute_input":"2024-04-18T17:58:02.867982Z","iopub.status.idle":"2024-04-18T17:58:02.881536Z","shell.execute_reply.started":"2024-04-18T17:58:02.867952Z","shell.execute_reply":"2024-04-18T17:58:02.880703Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#torch.multiprocessing.set_start_method('spawn')\ncheckpointing = ModelCheckpoint(monitor=\"val_loss\",\n                                dirpath='/kaggle/working/',\n                                filename='unet-epoch-{epoch}-{val_loss:.2f}-{val_dice:.2f}-{val_jaccard:.2f}', \n                                save_top_k=-1)\nes = EarlyStopping(monitor=\"val_loss\")\n\ntrainer = pl.Trainer(precision=16, \n                     devices=2, \n                     accelerator=\"gpu\",\n                     strategy=\"ddp_notebook\", \n                     max_epochs=10, \n                     callbacks=[es, checkpointing])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:02.882631Z","iopub.execute_input":"2024-04-18T17:58:02.882895Z","iopub.status.idle":"2024-04-18T17:58:03.584809Z","shell.execute_reply.started":"2024-04-18T17:58:02.882872Z","shell.execute_reply":"2024-04-18T17:58:03.583958Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\nINFO: Using 16bit Automatic Mixed Precision (AMP)\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"net = U_Net(img_ch=1, output_ch=1)\nlr = 1e-3\n#loss = nn.BCELoss()\n#loss = nn.BCEWithLogitsLoss()\nloss = GeneralizedDiceFocalLoss()\n#dice_metric = dice_coeff_binary()\njaccard_index_metric = BinaryJaccardIndex()\n# model.load_state_dict(checkpoint['state_dict'])\n# #optimizer.load_state_dict(checkpoint['optimizer_states'])\n# epoch = checkpoint['epoch']\n#checkpoint = torch.load('/kaggle/input/unet/pytorch/unet-epoch-1/1/unet-epoch-epoch1-val_loss0.03-val_dice0.41.ckpt')\n#unet_weights = checkpoint['state_dict']\n\nmodel = U_Net_DDP(net, lr, loss, jaccard_index_metric)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:03.586185Z","iopub.execute_input":"2024-04-18T17:58:03.586628Z","iopub.status.idle":"2024-04-18T17:58:03.987335Z","shell.execute_reply.started":"2024-04-18T17:58:03.586594Z","shell.execute_reply":"2024-04-18T17:58:03.986332Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, train_dataloader, validation_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:58:03.988926Z","iopub.execute_input":"2024-04-18T17:58:03.989332Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"INFO: ----------------------------------------------------------------------------------------------------\ndistributed_backend=nccl\nAll distributed processes registered. Starting with 2 processes\n----------------------------------------------------------------------------------------------------\n\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /kaggle/working exists and is not empty.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ede673e52c30435aaa69f5133674a87d"}},"metadata":{}}]},{"cell_type":"code","source":"!cd /kaggle/working  # Assuming the folder is in the working directory\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -czvf checkpoints.zip -C . .","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}