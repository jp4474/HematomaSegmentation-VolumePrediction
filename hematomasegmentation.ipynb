{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8150909,"sourceType":"datasetVersion","datasetId":4773550},{"sourceId":31710,"sourceType":"modelInstanceVersion","modelInstanceId":26595}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install monai\n!pip install lightning\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:12:58.064357Z","iopub.execute_input":"2024-04-20T02:12:58.064728Z","iopub.status.idle":"2024-04-20T02:13:28.347902Z","shell.execute_reply.started":"2024-04-20T02:12:58.064698Z","shell.execute_reply":"2024-04-20T02:13:28.346748Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.3.0-202310121228-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\nDownloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: monai\nSuccessfully installed monai-1.3.0\nCollecting lightning\n  Downloading lightning-2.2.2-py3-none-any.whl.metadata (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m907.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\nRequirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.0)\nRequirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.2)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: torch<4.0,>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.3.2)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.1)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\nDownloading lightning-2.2.2-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lightning\nSuccessfully installed lightning-2.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil\nimport glob\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n#import nibabel as nib\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\nfrom torchmetrics.classification import BinaryJaccardIndex, Dice, JaccardIndex\nimport torch.distributed as dist\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport torch.multiprocessing as mp\nfrom torch.nn.modules.loss import BCEWithLogitsLoss\nfrom monai.losses.dice import *","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:13:28.349748Z","iopub.execute_input":"2024-04-20T02:13:28.350054Z","iopub.status.idle":"2024-04-20T02:14:14.855697Z","shell.execute_reply.started":"2024-04-20T02:13:28.350025Z","shell.execute_reply":"2024-04-20T02:14:14.854851Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-20 02:14:06.947242: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-20 02:14:06.947377: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-20 02:14:07.053294: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from monai.data import DataLoader \n# , ArrayDataset\n# from torch.optim.lr_scheduler import CosineAnnealingLR\n# from monai.transforms import (\n#     EnsureChannelFirst,\n#     AsDiscrete,\n#     Compose,\n#     LoadImage,\n#     ScaleIntensity,\n# )\nimport pytorch_lightning as pl\nimport lightning\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:14:14.856910Z","iopub.execute_input":"2024-04-20T02:14:14.857545Z","iopub.status.idle":"2024-04-20T02:14:15.319413Z","shell.execute_reply.started":"2024-04-20T02:14:14.857517Z","shell.execute_reply":"2024-04-20T02:14:15.318669Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"class BraTSDataset(Dataset):    \n    def __init__(self, data_root_folder, folder = '', n_sample=None):\n        main_folder = os.path.join(data_root_folder, folder)\n        self.folder_path = os.path.join(main_folder, 'slice')\n        #self.file_names = sorted(os.listdir(self.folder_path))[:n_sample]\n\n\n    def __getitem__(self, index):\n        file_name = os.listdir(self.folder_path)[index]\n        #file_name = self.file_names[index]\n        sample = np.load(os.path.join(self.folder_path, file_name))\n        #eps = 0.0001\n        img = sample[0,:,:]\n        #img = img.resize((256, 256)) \n        diff = np.subtract(img.max(), img.min(), dtype=np.float64)\n        denom = np.clip(diff, a_min=1e-8, a_max=None)\n        img = (img - img.min()) / denom\n        mask = sample[1, :, :]\n        #mask= mask.resize((256, 256)) \n        mask[mask>0.0] = 1.0\n        mask[mask==0.0] = 0\n        img_as_tensor = np.expand_dims(img, axis=0)\n        mask_as_tensor = np.expand_dims(mask, axis=0)\n        img_as_tensor = torch.from_numpy(img_as_tensor)\n        mask_as_tensor = torch.from_numpy(mask_as_tensor)\n        \n        #return img_as_tensor, mask_as_tensor\n        return {\n            'image': img_as_tensor.type(torch.FloatTensor),\n            'mask': mask_as_tensor.type(torch.LongTensor),\n            'img_id': file_name\n        }\n \n    def __len__(self):\n        return len(os.listdir(self.folder_path))\n        #return len(self.file_names)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:14:19.247260Z","iopub.execute_input":"2024-04-20T02:14:19.247679Z","iopub.status.idle":"2024-04-20T02:14:19.258482Z","shell.execute_reply.started":"2024-04-20T02:14:19.247649Z","shell.execute_reply":"2024-04-20T02:14:19.257443Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"data_root_folder = '/kaggle/input/brats-dataset/full_raw - Copy'\ntrain_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'train')\nval_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'val')\ntest_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'test')","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:14:21.102038Z","iopub.execute_input":"2024-04-20T02:14:21.102413Z","iopub.status.idle":"2024-04-20T02:14:21.107438Z","shell.execute_reply.started":"2024-04-20T02:14:21.102385Z","shell.execute_reply":"2024-04-20T02:14:21.106487Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\n#device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:14:22.046081Z","iopub.execute_input":"2024-04-20T02:14:22.046456Z","iopub.status.idle":"2024-04-20T02:14:22.050726Z","shell.execute_reply.started":"2024-04-20T02:14:22.046426Z","shell.execute_reply":"2024-04-20T02:14:22.049742Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\nvalidation_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=2)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:14:22.971821Z","iopub.execute_input":"2024-04-20T02:14:22.972177Z","iopub.status.idle":"2024-04-20T02:14:24.036924Z","shell.execute_reply.started":"2024-04-20T02:14:22.972149Z","shell.execute_reply":"2024-04-20T02:14:24.036029Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Pre-trained model","metadata":{}},{"cell_type":"code","source":"!pip install pretrained-backbones-unet\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from backbones_unet.model.unet import Unet\nfrom backbones_unet.utils.dataset import SemanticSegmentationDataset\nfrom backbones_unet.model.losses import DiceLoss\nfrom backbones_unet.utils.trainer import Trainer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(iter(train_dataloader))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Unet(\n    backbone='convnext_base', # backbone network name\n    in_channels=1,            # input channels (1 for gray-scale images, 3 for RGB, etc.)\n    num_classes=2,            # output channels (number of classes in your dataset)\n)\n\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.AdamW(params, 1e-4) \n\ntrainer = Trainer(\n    model,                    # UNet model with pretrained backbone\n    criterion=DiceLoss(),     # loss function for model convergence\n    optimizer=optimizer,      # optimizer for regularization\n    epochs=10                 # number of epochs for model training\n)\n\ntrainer.fit(train_dataloader, validation_dataloader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sub Classes for U-Net and Attention U-Net","metadata":{}},{"cell_type":"code","source":"class conv_block(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(conv_block, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass resconv_block(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(resconv_block, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n        self.Conv_1x1 = nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, x):\n\n        residual = self.Conv_1x1(x)\n        x = self.conv(x)\n\n        return residual + x\n\n\nclass up_conv(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(up_conv, self).__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.up(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:14:27.992523Z","iopub.execute_input":"2024-04-20T02:14:27.993421Z","iopub.status.idle":"2024-04-20T02:14:28.006315Z","shell.execute_reply.started":"2024-04-20T02:14:27.993383Z","shell.execute_reply":"2024-04-20T02:14:28.005127Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# U-Net","metadata":{}},{"cell_type":"code","source":"class U_Net(nn.Module):\n    def __init__(self, img_ch=3, output_ch=2, first_layer_numKernel=64, name = \"U_Net\"):\n        super(U_Net, self).__init__()\n        self.name = name\n        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch, ch_out=first_layer_numKernel)\n        self.Conv2 = conv_block(ch_in=first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n        self.Conv3 = conv_block(ch_in=2 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n        self.Conv4 = conv_block(ch_in=4 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n        self.Conv5 = conv_block(ch_in=8 * first_layer_numKernel, ch_out=16 * first_layer_numKernel)\n\n        self.Up5 = up_conv(ch_in=16 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n        self.Up_conv5 = conv_block(ch_in=16 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n\n        self.Up4 = up_conv(ch_in=8 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n        self.Up_conv4 = conv_block(ch_in=8 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n\n        self.Up3 = up_conv(ch_in=4 * first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n        self.Up_conv3 = conv_block(ch_in=4 * first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n\n        self.Up2 = up_conv(ch_in=2 * first_layer_numKernel, ch_out=first_layer_numKernel)\n        self.Up_conv2 = conv_block(ch_in=2 * first_layer_numKernel, ch_out=first_layer_numKernel)\n\n        self.Conv_1x1 = nn.Sequential(\n            nn.Conv2d(first_layer_numKernel, output_ch, kernel_size=1, stride=1, padding=0), nn.Sigmoid() # Use sigmoid activation for binary segmentation\n        )\n        # self.Conv_1x1 =  nn.Conv2d(first_layer_numKernel, output_ch, kernel_size = 1, stride = 1, padding = 0)\n\n    def forward(self, x):\n\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n\n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        d5 = torch.cat((x4, d5), dim=1)\n\n        d5 = self.Up_conv5(d5)\n\n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3, d4), dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2, d3), dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1, d2), dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n        \n        return d1","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:14:53.105266Z","iopub.execute_input":"2024-04-20T02:14:53.105908Z","iopub.status.idle":"2024-04-20T02:14:53.123173Z","shell.execute_reply.started":"2024-04-20T02:14:53.105873Z","shell.execute_reply":"2024-04-20T02:14:53.122064Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def dice_coeff_binary(y_pred, y_true):\n        \"\"\"Values must be only zero or one.\"\"\"\n        y_pred[y_pred >= 0.5] = 1\n        y_pred[y_pred < 0.5] = 0\n        eps = 0.0001\n        inter = torch.dot(y_pred.view(-1).float(), y_true.view(-1).float())\n        union = torch.sum(y_pred.float()) + torch.sum(y_true.float())\n        return ((2 * inter.float() + eps) / (union.float() + eps))","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:14:57.563622Z","iopub.execute_input":"2024-04-20T02:14:57.564001Z","iopub.status.idle":"2024-04-20T02:14:57.570440Z","shell.execute_reply.started":"2024-04-20T02:14:57.563971Z","shell.execute_reply":"2024-04-20T02:14:57.569362Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"next(iter(train_dataloader))['mask'].shape","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:14:28.037248Z","iopub.execute_input":"2024-04-20T02:14:28.037529Z","iopub.status.idle":"2024-04-20T02:14:34.605437Z","shell.execute_reply.started":"2024-04-20T02:14:28.037504Z","shell.execute_reply":"2024-04-20T02:14:34.604409Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"torch.Size([16, 1, 240, 240])"},"metadata":{}}]},{"cell_type":"code","source":"class U_Net_DDP(pl.LightningModule):\n    def __init__(self, net, lr, loss, jaccard, batch_size):\n        super().__init__()\n        self.net = net\n        self.lr = lr\n        self.loss = loss \n        #self.dice = dice\n        self.jaccard = jaccard\n        self.sigmoid = nn.Sigmoid()\n        self.batch_size = batch_size\n        \n    def forward(self, x):\n        return self.net(x)\n    \n    def training_step(self, batch, batch_idx):\n        imgs = batch['image']\n        true_masks = batch['mask'] #.unsqueeze(1)\n        y_pred = self(imgs)  \n        loss = self.loss(y_pred, true_masks)\n        \n        #y_pred = (y_pred >= 0.5).float()\n        y_pred = torch.argmax(y_pred, dim=1)\n        y_pred = y_pred.unsqueeze(1)\n\n        batch_dice_score = dice_coeff_binary(y_pred, true_masks)\n        batch_jaccard_score = jaccard_index_metric(y_pred, true_masks)\n        \n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True, batch_size = self.batch_size)\n        self.log(\"train_dice\", batch_dice_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True,  batch_size = self.batch_size)\n        self.log(\"train_jaccard\", batch_jaccard_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True,  batch_size = self.batch_size)\n\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        imgs = batch['image'] #.float()\n        true_masks = batch['mask'] #.unsqueeze(1)\n        \n        y_pred = self(imgs)\n        #y_pred = (y_pred >= 0.5).float()\n        loss = self.loss(y_pred, true_masks)\n\n        y_pred = torch.argmax(y_pred, dim=1)\n        y_pred = y_pred.unsqueeze(1)\n        \n\n        batch_dice_score = dice_coeff_binary(y_pred, true_masks)\n        batch_jaccard_score = jaccard_index_metric(y_pred, true_masks)\n        \n        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True,  batch_size = self.batch_size)\n        self.log(\"val_dice\", batch_dice_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True,  batch_size = self.batch_size)\n        self.log(\"val_jaccard\", batch_dice_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True,  batch_size = self.batch_size)\n        \n        return loss\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n        #scheduler = CosineAnnealingLR(optimizer, self.trainer.max_epochs * 200, 0)\n        return [optimizer] #, [scheduler]","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:14:59.883621Z","iopub.execute_input":"2024-04-20T02:14:59.884818Z","iopub.status.idle":"2024-04-20T02:14:59.903236Z","shell.execute_reply.started":"2024-04-20T02:14:59.884777Z","shell.execute_reply":"2024-04-20T02:14:59.901914Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#torch.multiprocessing.set_start_method('spawn')\ncheckpointing = ModelCheckpoint(monitor=\"val_loss\",\n                                dirpath='/kaggle/working/',\n                                filename='unet-epoch-{epoch}-{val_loss:.2f}-{val_dice:.2f}-{val_jaccard:.2f}', \n                                save_top_k=-1)\nes = EarlyStopping(monitor=\"val_loss\")\n\ntrainer = pl.Trainer(precision=16, \n                     devices=2, \n                     accelerator=\"gpu\",\n                     strategy=\"ddp_notebook\", \n                     max_epochs=10, \n                     callbacks=[es, checkpointing])","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:15:01.973951Z","iopub.execute_input":"2024-04-20T02:15:01.974836Z","iopub.status.idle":"2024-04-20T02:15:02.625112Z","shell.execute_reply.started":"2024-04-20T02:15:01.974801Z","shell.execute_reply":"2024-04-20T02:15:02.624135Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\nINFO: Using 16bit Automatic Mixed Precision (AMP)\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"net = U_Net(img_ch=1, output_ch=2)\nlr = 1e-3\nloss = nn.CrossEntropyLoss()\n#loss = nn.BCEWithLogitsLoss()\n#loss = GeneralizedDiceFocalLoss()\n#dice_metric = dice_coeff_binary()\njaccard_index_metric = BinaryJaccardIndex()\n# model.load_state_dict(checkpoint['state_dict'])\n# #optimizer.load_state_dict(checkpoint['optimizer_states'])\n# epoch = checkpoint['epoch']\n#checkpoint = torch.load('/kaggle/input/unet/pytorch/unet-epoch-1/1/unet-epoch-epoch1-val_loss0.03-val_dice0.41.ckpt')\n#unet_weights = checkpoint['state_dict']\n\nmodel = U_Net_DDP(net, lr, loss, jaccard_index_metric, BATCH_SIZE)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:15:04.209231Z","iopub.execute_input":"2024-04-20T02:15:04.209652Z","iopub.status.idle":"2024-04-20T02:15:04.566665Z","shell.execute_reply.started":"2024-04-20T02:15:04.209602Z","shell.execute_reply":"2024-04-20T02:15:04.565878Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, train_dataloader, validation_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T02:15:05.921613Z","iopub.execute_input":"2024-04-20T02:15:05.922030Z","iopub.status.idle":"2024-04-20T02:15:06.758801Z","shell.execute_reply.started":"2024-04-20T02:15:05.922001Z","shell.execute_reply":"2024-04-20T02:15:06.757523Z"},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py:110\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Launches processes that run the given function in parallel.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03mThe function is allowed to have a return value. However, when all processes join, only the return value\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfork\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforkserver\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 110\u001b[0m     \u001b[43m_check_bad_cuda_fork\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    112\u001b[0m     _check_missing_main_guard()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning_fabric/strategies/launchers/multiprocessing.py:208\u001b[0m, in \u001b[0;36m_check_bad_cuda_fork\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_INTERACTIVE:\n\u001b[1;32m    207\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m You will have to restart the Python kernel.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(message)\n","\u001b[0;31mRuntimeError\u001b[0m: Lightning can't create new processes if CUDA is already initialized. Did you manually call `torch.cuda.*` functions, have moved the model to the device, or allocated memory on the GPU any other way? Please remove any such calls, or change the selected strategy. You will have to restart the Python kernel."],"ename":"RuntimeError","evalue":"Lightning can't create new processes if CUDA is already initialized. Did you manually call `torch.cuda.*` functions, have moved the model to the device, or allocated memory on the GPU any other way? Please remove any such calls, or change the selected strategy. You will have to restart the Python kernel.","output_type":"error"}]},{"cell_type":"code","source":"!cd /kaggle/working  # Assuming the folder is in the working directory\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -czvf checkpoints.zip -C . .","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}