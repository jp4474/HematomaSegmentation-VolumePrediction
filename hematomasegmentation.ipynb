{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8086534,"sourceType":"datasetVersion","datasetId":4773550},{"sourceId":31710,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":26595}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install monai\n!pip install lightning\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:42:54.914309Z","iopub.execute_input":"2024-04-16T04:42:54.914641Z","iopub.status.idle":"2024-04-16T04:43:25.837915Z","shell.execute_reply.started":"2024-04-16T04:42:54.914612Z","shell.execute_reply":"2024-04-16T04:43:25.836901Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.3.0-202310121228-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\nDownloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: monai\nSuccessfully installed monai-1.3.0\nCollecting lightning\n  Downloading lightning-2.2.2-py3-none-any.whl.metadata (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m871.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\nRequirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.0)\nRequirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.2)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: torch<4.0,>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.3.2)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.1)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\nDownloading lightning-2.2.2-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lightning\nSuccessfully installed lightning-2.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil\nimport glob\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n#import nibabel as nib\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\nfrom torchmetrics.classification import BinaryJaccardIndex, Dice, JaccardIndex\nimport torch.distributed as dist\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport torch.multiprocessing as mp\nfrom torch.nn.modules.loss import BCEWithLogitsLoss\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:43:25.840577Z","iopub.execute_input":"2024-04-16T04:43:25.841318Z","iopub.status.idle":"2024-04-16T04:43:37.027332Z","shell.execute_reply.started":"2024-04-16T04:43:25.841277Z","shell.execute_reply":"2024-04-16T04:43:37.026323Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from monai.data import DataLoader \n# , ArrayDataset\n# from torch.optim.lr_scheduler import CosineAnnealingLR\n# from monai.transforms import (\n#     EnsureChannelFirst,\n#     AsDiscrete,\n#     Compose,\n#     LoadImage,\n#     ScaleIntensity,\n# )\nimport pytorch_lightning as pl\nimport lightning\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:43:37.028562Z","iopub.execute_input":"2024-04-16T04:43:37.029043Z","iopub.status.idle":"2024-04-16T04:44:16.496677Z","shell.execute_reply.started":"2024-04-16T04:43:37.029008Z","shell.execute_reply":"2024-04-16T04:44:16.495839Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-04-16 04:44:06.969756: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-16 04:44:06.969872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-16 04:44:07.130054: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"class BraTSDataset(Dataset):    \n    def __init__(self, data_root_folder, folder = '', n_sample=None):\n        main_folder = os.path.join(data_root_folder, folder)\n        self.folder_path = os.path.join(main_folder, 'slice')\n        #self.file_names = sorted(os.listdir(self.folder_path))[:n_sample]\n\n\n    def __getitem__(self, index):\n        file_name = os.listdir(self.folder_path)[index]\n        #file_name = self.file_names[index]\n        sample = torch.from_numpy(np.load(os.path.join(self.folder_path, file_name)))\n        img_as_tensor = np.expand_dims(sample[0,:,:], axis=0)\n        mask_as_tensor = np.expand_dims(sample[1,:,:], axis=0)\n        return {\n            'image': img_as_tensor,\n            'mask': mask_as_tensor,\n            'img_id': file_name\n        }\n \n    def __len__(self):\n        return len(os.listdir(self.folder_path))\n        #return len(self.file_names)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:44:16.497801Z","iopub.execute_input":"2024-04-16T04:44:16.498582Z","iopub.status.idle":"2024-04-16T04:44:16.506888Z","shell.execute_reply.started":"2024-04-16T04:44:16.498554Z","shell.execute_reply":"2024-04-16T04:44:16.505875Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"data_root_folder = '/kaggle/input/brats-dataset/full_raw - Copy'\ntrain_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'train')\nval_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'val')\ntest_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'test')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:44:16.510283Z","iopub.execute_input":"2024-04-16T04:44:16.510678Z","iopub.status.idle":"2024-04-16T04:44:16.528301Z","shell.execute_reply.started":"2024-04-16T04:44:16.510638Z","shell.execute_reply":"2024-04-16T04:44:16.527376Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\n#device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:44:16.529549Z","iopub.execute_input":"2024-04-16T04:44:16.529836Z","iopub.status.idle":"2024-04-16T04:44:16.541801Z","shell.execute_reply.started":"2024-04-16T04:44:16.529813Z","shell.execute_reply":"2024-04-16T04:44:16.541105Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\nvalidation_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=2)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:44:16.543332Z","iopub.execute_input":"2024-04-16T04:44:16.543744Z","iopub.status.idle":"2024-04-16T04:44:17.858696Z","shell.execute_reply.started":"2024-04-16T04:44:16.543711Z","shell.execute_reply":"2024-04-16T04:44:17.857873Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Sub Classes for U-Net and Attention U-Net","metadata":{}},{"cell_type":"code","source":"class conv_block(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(conv_block, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass resconv_block(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(resconv_block, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n        self.Conv_1x1 = nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, x):\n\n        residual = self.Conv_1x1(x)\n        x = self.conv(x)\n\n        return residual + x\n\n\nclass up_conv(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(up_conv, self).__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.up(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:44:17.860139Z","iopub.execute_input":"2024-04-16T04:44:17.860937Z","iopub.status.idle":"2024-04-16T04:44:17.874081Z","shell.execute_reply.started":"2024-04-16T04:44:17.860874Z","shell.execute_reply":"2024-04-16T04:44:17.873169Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# U-Net","metadata":{}},{"cell_type":"code","source":"class U_Net(nn.Module):\n    def __init__(self, img_ch=3, output_ch=1, first_layer_numKernel=64, name = \"U_Net\"):\n        super(U_Net, self).__init__()\n        self.name = name\n        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch, ch_out=first_layer_numKernel)\n        self.Conv2 = conv_block(ch_in=first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n        self.Conv3 = conv_block(ch_in=2 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n        self.Conv4 = conv_block(ch_in=4 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n        self.Conv5 = conv_block(ch_in=8 * first_layer_numKernel, ch_out=16 * first_layer_numKernel)\n\n        self.Up5 = up_conv(ch_in=16 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n        self.Up_conv5 = conv_block(ch_in=16 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n\n        self.Up4 = up_conv(ch_in=8 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n        self.Up_conv4 = conv_block(ch_in=8 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n\n        self.Up3 = up_conv(ch_in=4 * first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n        self.Up_conv3 = conv_block(ch_in=4 * first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n\n        self.Up2 = up_conv(ch_in=2 * first_layer_numKernel, ch_out=first_layer_numKernel)\n        self.Up_conv2 = conv_block(ch_in=2 * first_layer_numKernel, ch_out=first_layer_numKernel)\n\n        self.Conv_1x1 = nn.Sequential(\n            nn.Conv2d(first_layer_numKernel, output_ch, kernel_size=1, stride=1, padding=0) # Use sigmoid activation for binary segmentation\n        )\n        # self.Conv_1x1 =  nn.Conv2d(first_layer_numKernel, output_ch, kernel_size = 1, stride = 1, padding = 0)\n\n    def forward(self, x):\n\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n\n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        d5 = torch.cat((x4, d5), dim=1)\n\n        d5 = self.Up_conv5(d5)\n\n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3, d4), dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2, d3), dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1, d2), dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n        \n        return d1","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:44:17.875486Z","iopub.execute_input":"2024-04-16T04:44:17.876113Z","iopub.status.idle":"2024-04-16T04:44:17.892135Z","shell.execute_reply.started":"2024-04-16T04:44:17.876075Z","shell.execute_reply":"2024-04-16T04:44:17.891225Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class U_Net_DDP(pl.LightningModule):\n    def __init__(self, net, lr, loss, dice, jaccard):\n        super().__init__()\n        self.net = net\n        self.lr = lr\n        self.loss = loss \n        self.dice = dice\n        self.jaccard = jaccard\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        return self.net(x)\n    \n    def training_step(self, batch, batch_idx):\n        imgs = batch['image'].float()\n        true_masks = batch['mask']\n\n        y_pred = self(imgs)\n        loss = self.loss(y_pred, true_masks.float())\n        #y_pred = (y_pred >= 0.5).float()\n        y_pred = self.sigmoid(y_pred)\n\n        batch_dice_score = dice_metric(y_pred, true_masks)\n        batch_jaccard_score = jaccard_index_metric(y_pred, true_masks)\n        \n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        self.log(\"dice\", batch_dice_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        self.log(\"jaccard\", batch_jaccard_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        \n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        imgs = batch['image'].float()\n        true_masks = batch['mask']\n        \n        y_pred = self(imgs)\n        loss = self.loss(y_pred, true_masks.float())\n        #y_pred = (y_pred >= 0.5).float()\n        y_pred = self.sigmoid(y_pred)\n\n        batch_dice_score = dice_metric(y_pred, true_masks)\n        batch_jaccard_score = jaccard_index_metric(y_pred, true_masks)\n        \n        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        self.log(\"val_dice\", batch_dice_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        self.log(\"val_jaccard\", batch_dice_score, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n        \n        return loss\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n        #scheduler = CosineAnnealingLR(optimizer, self.trainer.max_epochs * 200, 0)\n        return [optimizer] #, [scheduler]","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:44:17.893293Z","iopub.execute_input":"2024-04-16T04:44:17.893939Z","iopub.status.idle":"2024-04-16T04:44:17.907407Z","shell.execute_reply.started":"2024-04-16T04:44:17.893892Z","shell.execute_reply":"2024-04-16T04:44:17.906597Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#torch.multiprocessing.set_start_method('spawn')\ncheckpointing = ModelCheckpoint(monitor=\"val_loss\",\n                                dirpath='/kaggle/working/',\n                                filename='unet-epoch-{epoch}-{val_loss:.2f}-{val_dice:.2f}-{val_jaccard:.2f}')\nes = EarlyStopping(monitor=\"val_loss\")\n\ntrainer = pl.Trainer(precision=16, \n                     devices=2, \n                     accelerator=\"gpu\",\n                     strategy=\"ddp_notebook\", \n                     max_epochs=5, \n                     callbacks=[es, checkpointing])","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:44:17.908658Z","iopub.execute_input":"2024-04-16T04:44:17.909538Z","iopub.status.idle":"2024-04-16T04:44:18.611714Z","shell.execute_reply.started":"2024-04-16T04:44:17.909496Z","shell.execute_reply":"2024-04-16T04:44:18.610860Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\nINFO: Using 16bit Automatic Mixed Precision (AMP)\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"net = U_Net(img_ch=1, output_ch=1)\nlr = 1e-3\n#loss = nn.BCELoss()\nloss = nn.BCEWithLogitsLoss()\n#loss = checkpoint['loss']\ndice_metric = Dice()\njaccard_index_metric = BinaryJaccardIndex()\n# model = U_Net_DDP(net, lr, loss, dice_metric, jaccard_index_metric)\n# model.load_state_dict(checkpoint['state_dict'])\n# #optimizer.load_state_dict(checkpoint['optimizer_states'])\n# epoch = checkpoint['epoch']\n#checkpoint = torch.load('/kaggle/input/unet/pytorch/unet-epoch-1/1/unet-epoch-epoch1-val_loss0.03-val_dice0.41.ckpt')\n#unet_weights = checkpoint['state_dict']\n\nmodel = U_Net_DDP(net, lr, loss, dice_metric, jaccard_index_metric)\n#model = model.load_from_checkpoint('/kaggle/input/unet/pytorch/unet-epoch-1/1/unet-epoch-epoch1-val_loss0.03-val_dice0.41.ckpt')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:44:18.612920Z","iopub.execute_input":"2024-04-16T04:44:18.613265Z","iopub.status.idle":"2024-04-16T04:44:18.988197Z","shell.execute_reply.started":"2024-04-16T04:44:18.613233Z","shell.execute_reply":"2024-04-16T04:44:18.987140Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, train_dataloader, validation_dataloader, ckpt_path='/kaggle/input/unet/pytorch/unet-epoch-1/1/unet-epoch-epoch1-val_loss0.03-val_dice0.41.ckpt')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T04:44:18.989565Z","iopub.execute_input":"2024-04-16T04:44:18.989965Z","iopub.status.idle":"2024-04-16T10:28:18.943045Z","shell.execute_reply.started":"2024-04-16T04:44:18.989928Z","shell.execute_reply":"2024-04-16T10:28:18.940534Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"INFO: ----------------------------------------------------------------------------------------------------\ndistributed_backend=nccl\nAll distributed processes registered. Starting with 2 processes\n----------------------------------------------------------------------------------------------------\n\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /kaggle/working exists and is not empty.\nINFO: Restoring states from the checkpoint path at /kaggle/input/unet/pytorch/unet-epoch-1/1/unet-epoch-epoch1-val_loss0.03-val_dice0.41.ckpt\nINFO: Restored all states from the checkpoint at /kaggle/input/unet/pytorch/unet-epoch-1/1/unet-epoch-epoch1-val_loss0.03-val_dice0.41.ckpt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6f709294d084416812837d50f1da123"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 13. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=5` reached.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd /kaggle/working  # Assuming the folder is in the working directory\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T11:37:15.222789Z","iopub.execute_input":"2024-04-16T11:37:15.223049Z","iopub.status.idle":"2024-04-16T11:37:16.174656Z","shell.execute_reply.started":"2024-04-16T11:37:15.223017Z","shell.execute_reply":"2024-04-16T11:37:16.173390Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:28:20.015622Z","iopub.execute_input":"2024-04-16T10:28:20.015972Z","iopub.status.idle":"2024-04-16T10:28:21.098171Z","shell.execute_reply.started":"2024-04-16T10:28:20.015936Z","shell.execute_reply":"2024-04-16T10:28:21.097065Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":" lightning_logs\n my_work.zip\n'unet-epoch-epoch=2-val_loss=0.02-val_dice=0.46-val_jaccard=0.46.ckpt'\n'unet-epoch-epoch=2-val_loss=0.82-val_dice=0.00.ckpt'\n","output_type":"stream"}]},{"cell_type":"code","source":"!tar -czvf checkpoints.zip -C . .","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:28:21.099569Z","iopub.execute_input":"2024-04-16T10:28:21.099882Z","iopub.status.idle":"2024-04-16T10:29:28.531342Z","shell.execute_reply.started":"2024-04-16T10:28:21.099854Z","shell.execute_reply":"2024-04-16T10:29:28.530254Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"./\n./unet-epoch-epoch=2-val_loss=0.82-val_dice=0.00.ckpt\n./.virtual_documents/\n./my_work.zip\n./unet-epoch-epoch=2-val_loss=0.02-val_dice=0.46-val_jaccard=0.46.ckpt\n./lightning_logs/\n./lightning_logs/version_5/\n./lightning_logs/version_5/hparams.yaml\n./lightning_logs/version_5/events.out.tfevents.1713131230.93725de63ae6.589.0\n./lightning_logs/version_6/\n./lightning_logs/version_6/events.out.tfevents.1713131297.93725de63ae6.816.0\n./lightning_logs/version_6/hparams.yaml\n./lightning_logs/version_10/\n./lightning_logs/version_10/events.out.tfevents.1713205721.b491f061d606.83.0\n./lightning_logs/version_10/hparams.yaml\n./lightning_logs/version_8/\n./lightning_logs/version_8/events.out.tfevents.1713131576.93725de63ae6.1710.0\n./lightning_logs/version_8/hparams.yaml\n./lightning_logs/version_0/\n./lightning_logs/version_0/events.out.tfevents.1713130115.93725de63ae6.88.0\n./lightning_logs/version_0/hparams.yaml\n./lightning_logs/version_2/\n./lightning_logs/version_2/hparams.yaml\n./lightning_logs/version_2/events.out.tfevents.1713130671.93725de63ae6.276.0\n./lightning_logs/version_7/\n./lightning_logs/version_7/hparams.yaml\n./lightning_logs/version_7/events.out.tfevents.1713131446.93725de63ae6.1566.0\n./lightning_logs/version_9/\n./lightning_logs/version_9/events.out.tfevents.1713131784.93725de63ae6.1817.0\n./lightning_logs/version_9/hparams.yaml\n./lightning_logs/version_11/\n./lightning_logs/version_11/events.out.tfevents.1713230979.29f3744382ca.83.0\n./lightning_logs/version_11/hparams.yaml\n./lightning_logs/version_12/\n./lightning_logs/version_12/events.out.tfevents.1713242662.a6d15e94ef2c.84.0\n./lightning_logs/version_12/hparams.yaml\n./lightning_logs/version_3/\n./lightning_logs/version_3/hparams.yaml\n./lightning_logs/version_3/events.out.tfevents.1713130903.93725de63ae6.375.0\n./lightning_logs/version_1/\n./lightning_logs/version_1/hparams.yaml\n./lightning_logs/version_1/events.out.tfevents.1713130388.93725de63ae6.177.0\n./lightning_logs/version_4/\n./lightning_logs/version_4/hparams.yaml\n./lightning_logs/version_4/events.out.tfevents.1713130935.93725de63ae6.482.0\ntar: .: file changed as we read it\n","output_type":"stream"}]}]}