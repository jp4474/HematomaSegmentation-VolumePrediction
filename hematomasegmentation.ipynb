{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8086534,"sourceType":"datasetVersion","datasetId":4773550}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport glob\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport nibabel as nib\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\nfrom torchmetrics.classification import BinaryJaccardIndex, Dice\nimport torch.distributed as dist\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport torch.multiprocessing as mp","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:31:42.537396Z","iopub.execute_input":"2024-04-12T20:31:42.537981Z","iopub.status.idle":"2024-04-12T20:31:42.545683Z","shell.execute_reply.started":"2024-04-12T20:31:42.537952Z","shell.execute_reply":"2024-04-12T20:31:42.544617Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"class BraTSDataset(Dataset):    \n    def __init__(self, data_root_folder, folder = '', n_sample=None):\n        main_folder = os.path.join(data_root_folder, folder)\n        self.folder_path = os.path.join(main_folder, 'slice')\n\n    def __getitem__(self, index):\n        file_name = os.listdir(self.folder_path)[index]\n        sample = torch.from_numpy(np.load(os.path.join(self.folder_path, file_name)))\n        img_as_tensor = np.expand_dims(sample[0,:,:], axis=0)\n        mask_as_tensor = np.expand_dims(sample[1,:,:], axis=0)\n        return {\n            'image': img_as_tensor,\n            'mask': mask_as_tensor,\n            'img_id': file_name\n        }\n \n    def __len__(self):\n        return len(os.listdir(self.folder_path))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:31:42.547664Z","iopub.execute_input":"2024-04-12T20:31:42.548361Z","iopub.status.idle":"2024-04-12T20:31:42.562225Z","shell.execute_reply.started":"2024-04-12T20:31:42.548330Z","shell.execute_reply":"2024-04-12T20:31:42.561327Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"data_root_folder = '/kaggle/input/brats-dataset/full_raw - Copy'\ntrain_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'train')\nval_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'val')\ntest_dataset = BraTSDataset(data_root_folder = data_root_folder, folder = 'test')","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:31:42.563242Z","iopub.execute_input":"2024-04-12T20:31:42.563538Z","iopub.status.idle":"2024-04-12T20:31:42.571454Z","shell.execute_reply.started":"2024-04-12T20:31:42.563515Z","shell.execute_reply":"2024-04-12T20:31:42.570598Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:31:42.572577Z","iopub.execute_input":"2024-04-12T20:31:42.572944Z","iopub.status.idle":"2024-04-12T20:31:42.604769Z","shell.execute_reply.started":"2024-04-12T20:31:42.572912Z","shell.execute_reply":"2024-04-12T20:31:42.604027Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nvalidation_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:31:42.606945Z","iopub.execute_input":"2024-04-12T20:31:42.607220Z","iopub.status.idle":"2024-04-12T20:31:44.800026Z","shell.execute_reply.started":"2024-04-12T20:31:42.607197Z","shell.execute_reply":"2024-04-12T20:31:44.799204Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Sub Classes for U-Net and Attention U-Net","metadata":{}},{"cell_type":"code","source":"class conv_block(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(conv_block, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass resconv_block(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(resconv_block, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n        self.Conv_1x1 = nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, x):\n\n        residual = self.Conv_1x1(x)\n        x = self.conv(x)\n\n        return residual + x\n\n\nclass up_conv(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(up_conv, self).__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n            nn.GroupNorm(32, ch_out),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.up(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:31:44.801163Z","iopub.execute_input":"2024-04-12T20:31:44.801470Z","iopub.status.idle":"2024-04-12T20:31:44.814097Z","shell.execute_reply.started":"2024-04-12T20:31:44.801441Z","shell.execute_reply":"2024-04-12T20:31:44.813169Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# U-Net","metadata":{}},{"cell_type":"code","source":"class U_Net(nn.Module):\n    def __init__(self, img_ch=3, output_ch=1, first_layer_numKernel=64, name = \"U_Net\"):\n        super(U_Net, self).__init__()\n        self.name = name\n        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.Conv1 = conv_block(ch_in=img_ch, ch_out=first_layer_numKernel)\n        self.Conv2 = conv_block(ch_in=first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n        self.Conv3 = conv_block(ch_in=2 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n        self.Conv4 = conv_block(ch_in=4 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n        self.Conv5 = conv_block(ch_in=8 * first_layer_numKernel, ch_out=16 * first_layer_numKernel)\n\n        self.Up5 = up_conv(ch_in=16 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n        self.Up_conv5 = conv_block(ch_in=16 * first_layer_numKernel, ch_out=8 * first_layer_numKernel)\n\n        self.Up4 = up_conv(ch_in=8 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n        self.Up_conv4 = conv_block(ch_in=8 * first_layer_numKernel, ch_out=4 * first_layer_numKernel)\n\n        self.Up3 = up_conv(ch_in=4 * first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n        self.Up_conv3 = conv_block(ch_in=4 * first_layer_numKernel, ch_out=2 * first_layer_numKernel)\n\n        self.Up2 = up_conv(ch_in=2 * first_layer_numKernel, ch_out=first_layer_numKernel)\n        self.Up_conv2 = conv_block(ch_in=2 * first_layer_numKernel, ch_out=first_layer_numKernel)\n\n        self.Conv_1x1 = nn.Sequential(\n            nn.Conv2d(first_layer_numKernel, output_ch, kernel_size=1, stride=1, padding=0), nn.Sigmoid()  # Use sigmoid activation for binary segmentation\n        )\n        # self.Conv_1x1 =  nn.Conv2d(first_layer_numKernel, output_ch, kernel_size = 1, stride = 1, padding = 0)\n\n    def forward(self, x):\n\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n\n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x5 = self.Conv5(x5)\n\n        # decoding + concat path\n        d5 = self.Up5(x5)\n        d5 = torch.cat((x4, d5), dim=1)\n\n        d5 = self.Up_conv5(d5)\n\n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3, d4), dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2, d3), dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1, d2), dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n        \n        #print(d1)\n\n        return d1","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:31:44.815461Z","iopub.execute_input":"2024-04-12T20:31:44.815767Z","iopub.status.idle":"2024-04-12T20:31:44.832609Z","shell.execute_reply.started":"2024-04-12T20:31:44.815745Z","shell.execute_reply":"2024-04-12T20:31:44.831860Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class EarlyStopper:\n    def __init__(self, patience=1, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.max_validation_dice = float('-inf')\n\n    def early_stop(self, validation_dice):\n        if validation_dice > self.max_validation_dice:\n            self.max_validation_dice = validation_dice\n            self.counter = 0\n        elif validation_dice < (self.max_validation_dice + self.min_delta):\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:31:44.834904Z","iopub.execute_input":"2024-04-12T20:31:44.835489Z","iopub.status.idle":"2024-04-12T20:31:44.844164Z","shell.execute_reply.started":"2024-04-12T20:31:44.835459Z","shell.execute_reply":"2024-04-12T20:31:44.843320Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"LR = 5e-3\nEPOCHS = 10 # this maybe too big?\n\n\nunet = U_Net(img_ch=1, output_ch=1).to(device)\n\noptimizer = torch.optim.AdamW(unet.parameters(), lr=LR)\nloss_function = nn.BCELoss()\nearly_stopper = EarlyStopper(patience=3, min_delta=0.02)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:31:44.845131Z","iopub.execute_input":"2024-04-12T20:31:44.845387Z","iopub.status.idle":"2024-04-12T20:31:45.992974Z","shell.execute_reply.started":"2024-04-12T20:31:44.845359Z","shell.execute_reply":"2024-04-12T20:31:45.992210Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(sum(p.numel() for p in unet.parameters() if p.requires_grad))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:31:45.994044Z","iopub.execute_input":"2024-04-12T20:31:45.994517Z","iopub.status.idle":"2024-04-12T20:31:46.000297Z","shell.execute_reply.started":"2024-04-12T20:31:45.994491Z","shell.execute_reply":"2024-04-12T20:31:45.999376Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"34525889\n","output_type":"stream"}]},{"cell_type":"code","source":"# The training function\ndef train_net(net, epochs, train_dataloader, valid_dataloader, optimizer, loss_function):\n\n    if not os.path.isdir('{0}'.format(net.name)):\n        os.mkdir('{0}'.format(net.name))\n    \n    n_train = len(train_dataloader)\n    n_valid = len(valid_dataloader)\n\n    train_loss, valid_loss = [], []\n    train_dice, valid_dice = [], []\n    train_jaccard, valid_jaccard = [], []\n    dice_metric = Dice()\n    jaccard_index_metric = BinaryJaccardIndex()\n\n    # Training\n    for epoch in range(epochs):\n        net.train()\n        train_batch_loss, train_batch_dice, train_batch_jaccard = [], [], []\n\n        for i, batch in enumerate(tqdm(train_dataloader)):\n            imgs = batch['image'].to(device).float()\n            true_masks = batch['mask']\n\n            # Produce the estimated mask using current weights\n            y_pred = net(imgs).cpu()\n\n            loss = loss_function(y_pred, true_masks.float())\n            train_batch_loss.append(loss.item())\n            \n            y_pred = (y_pred >= 0.5).float()\n\n            batch_dice_score = dice_metric(y_pred, true_masks)\n            train_batch_dice.append(batch_dice_score)\n\n            batch_jaccard_score = jaccard_index_metric(y_pred, true_masks)\n            train_batch_jaccard.append(batch_jaccard_score)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step() \n            if i == 50:\n                break\n\n            print(f'EPOCH {epoch + 1}/{epochs} - Training Batch {i+1}/{n_train} - Loss: {loss.item()}, DICE score: {batch_dice_score}, Jaccard score: {batch_jaccard_score}', end='\\r')\n        \n        train_loss.append(np.mean(train_batch_loss))\n        train_dice.append(np.mean(train_batch_dice))\n        train_jaccard.append(np.mean(train_batch_jaccard))\n\n        net.eval()\n        valid_batch_loss, valid_batch_dice, valid_batch_jaccard = [], [], []\n\n        # Validation\n        with torch.no_grad():\n            for i, batch in enumerate(tqdm(valid_dataloader)):\n                imgs = batch['image'].to(device).float()\n                true_masks = batch['mask'] #.to(device).float()\n    \n                y_pred = net(imgs).cpu()\n\n                loss = loss_function(y_pred, true_masks.float())\n                valid_batch_loss.append(loss.item())\n                \n                y_pred = (y_pred >= 0.5).float()\n\n                batch_dice_score = dice_metric(y_pred, true_masks)\n                valid_batch_dice.append(batch_dice_score)\n\n                batch_jaccard_score = jaccard_index_metric(y_pred, true_masks)\n                valid_batch_jaccard.append(batch_jaccard_score)\n     \n                print(f'EPOCH {epoch + 1}/{epochs} - Validation Batch {i+1}/{n_valid} - Loss: {loss.item()}, DICE score: {batch_dice_score}, Jaccard score: {batch_jaccard_score}', end='\\r')\n\n        valid_loss.append(np.mean(valid_batch_loss))\n        valid_dice.append(np.mean(valid_batch_dice))\n        valid_jaccard.append(np.mean(valid_batch_jaccard))\n        \n        if early_stopper.early_stop(np.mean(valid_batch_dice)):             \n            break \n\n        print(f'EPOCH {epoch + 1}/{epochs} - Training Loss: {np.mean(train_batch_loss)}, Training DICE score: {np.mean(train_batch_dice)}, Training Jaccard score: {np.mean(train_batch_jaccard)}, Validation Loss: {np.mean(valid_batch_loss)}, Validation DICE score: {np.mean(valid_batch_dice)}, Validation Jaccard score: {np.mean(valid_batch_jaccard)}')\n\n        torch.save(net.state_dict(), f'{net.name}/epoch_{epoch+1:3}.pth')\n\n    return train_loss, train_dice, train_jaccard, valid_loss, valid_dice, valid_jaccard","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:49:22.045150Z","iopub.execute_input":"2024-04-12T20:49:22.045491Z","iopub.status.idle":"2024-04-12T20:49:22.062454Z","shell.execute_reply.started":"2024-04-12T20:49:22.045464Z","shell.execute_reply":"2024-04-12T20:49:22.061393Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_loss, train_dice, train_jaccard, valid_loss, valid_dice, valid_jaccard = train_net(unet, EPOCHS, train_dataloader, validation_dataloader, optimizer, loss_function)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T20:49:22.064140Z","iopub.execute_input":"2024-04-12T20:49:22.064396Z","iopub.status.idle":"2024-04-12T20:51:13.106237Z","shell.execute_reply.started":"2024-04-12T20:49:22.064375Z","shell.execute_reply":"2024-04-12T20:51:13.104822Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8496 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3e6f98cc0694a21ae62da24f5621f04"}},"metadata":{}},{"name":"stdout","text":"EPOCH 1/10 - Training Batch 50/8496 - Loss: 0.03032330609858036, DICE score: 0.0, Jaccard score: 0.00\r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1812 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac0211eb444f4199967bface51304af7"}},"metadata":{}},{"name":"stdout","text":"EPOCH 1/10 - Validation Batch 72/1812 - Loss: 0.03402853384613991, DICE score: 0.0, Jaccard score: 0.00\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss, train_dice, train_jaccard, valid_loss, valid_dice, valid_jaccard \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43munet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[16], line 70\u001b[0m, in \u001b[0;36mtrain_net\u001b[0;34m(net, epochs, train_dataloader, valid_dataloader, optimizer, loss_function)\u001b[0m\n\u001b[1;32m     67\u001b[0m batch_dice_score \u001b[38;5;241m=\u001b[39m dice_metric(y_pred, true_masks)\n\u001b[1;32m     68\u001b[0m valid_batch_dice\u001b[38;5;241m.\u001b[39mappend(batch_dice_score)\n\u001b[0;32m---> 70\u001b[0m batch_jaccard_score \u001b[38;5;241m=\u001b[39m \u001b[43mjaccard_index_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m valid_batch_jaccard\u001b[38;5;241m.\u001b[39mappend(batch_jaccard_score)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Validation Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_valid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, DICE score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_dice_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Jaccard score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_jaccard_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/metric.py:304\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/metric.py:373\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/metric.py:466\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/classification/confusion_matrix.py:139\u001b[0m, in \u001b[0;36mBinaryConfusionMatrix.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 139\u001b[0m     \u001b[43m_binary_confusion_matrix_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _binary_confusion_matrix_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index)\n\u001b[1;32m    141\u001b[0m confmat \u001b[38;5;241m=\u001b[39m _binary_confusion_matrix_update(preds, target)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/functional/classification/confusion_matrix.py:97\u001b[0m, in \u001b[0;36m_binary_confusion_matrix_tensor_validation\u001b[0;34m(preds, target, ignore_index)\u001b[0m\n\u001b[1;32m     94\u001b[0m _check_same_shape(preds, target)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Check that target only contains {0,1} values or value in ignore_index\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m unique_values \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     check \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39many((unique_values \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (unique_values \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/functional.py:976\u001b[0m, in \u001b[0;36m_return_output\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> 976\u001b[0m output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/functional.py:890\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    882\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39munique_dim(\n\u001b[1;32m    883\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    884\u001b[0m         dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[1;32m    888\u001b[0m     )\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 890\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"#fixme: ","metadata":{}}]}